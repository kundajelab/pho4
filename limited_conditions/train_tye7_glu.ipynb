{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqdataloader.batchproducers import coordbased\n",
    "from seqdataloader.batchproducers.coordbased import coordstovals\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchproducers\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchtransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import keras_genomics\n",
    "from keras_genomics.layers.convolutional import RevCompConv1D\n",
    "import keras\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from seqdataloader.batchproducers import coordbased\n",
    "from seqdataloader.batchproducers.coordbased import coordstovals\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchproducers\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchtransformers\n",
    "\n",
    "def multinomial_nll(true_counts, logits):\n",
    "    \"\"\"Compute the multinomial negative log-likelihood\n",
    "    Args:\n",
    "      true_counts: observed count values\n",
    "      logits: predicted logit values\n",
    "    \"\"\"\n",
    "    counts_per_example = tf.reduce_sum(true_counts, axis=-1)\n",
    "    dist = tfp.distributions.Multinomial(total_count=counts_per_example,\n",
    "                                         logits=logits)\n",
    "    return (-tf.reduce_sum(dist.log_prob(true_counts)) / \n",
    "            tf.to_float(tf.shape(true_counts)[0]))\n",
    "\n",
    "\n",
    "#from https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/basepair/losses.py#L87\n",
    "class MultichannelMultinomialNLL(object):\n",
    "    def __init__(self, n):\n",
    "        self.__name__ = \"MultichannelMultinomialNLL\"\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, true_counts, logits):\n",
    "        for i in range(self.n):\n",
    "            loss = multinomial_nll(true_counts[..., i], logits[..., i])\n",
    "            if i == 0:\n",
    "                total = loss\n",
    "            else:\n",
    "                total += loss\n",
    "        return total\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"n\": self.n}\n",
    "\n",
    "#If we want to avoid zero-padding, then the input seq len will be determined\n",
    "# by parameters of the convolutions\n",
    "class AbstractProfileModel(object):\n",
    "\n",
    "    def get_output_profile_len(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_model(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "def trim_flanks_of_conv_layer(conv_layer, output_len, width_to_trim, filters):\n",
    "    layer = keras.layers.Lambda(\n",
    "        lambda x: x[:,\n",
    "          int(0.5*(width_to_trim)):-(width_to_trim-int(0.5*(width_to_trim)))],\n",
    "        output_shape=(output_len, filters))(conv_layer)\n",
    "    return layer\n",
    "\n",
    "#model architecture is based on \n",
    "#https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/basepair/models.py#L534\n",
    "#The non-cli parameters are specified in:\n",
    "# https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/src/chipnexus/train/seqmodel/joint-model-valid.gin\n",
    "#The cli parameters are in line 165 of:\n",
    "# https://docs.google.com/spreadsheets/d/1n3l2HXKSNpmNUOifD41uRzDEAgmOqXMQDxquRaz6WLg/edit#gid=0\n",
    "# which seems to match https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/src/chipnexus/train/seqmodel/ChIP-seq-default.gin\n",
    "class RcBPnetArch(AbstractProfileModel):   \n",
    "\n",
    "    def __init__(self, input_seq_len, c_task_weight, filters,\n",
    "                       n_dil_layers, conv1_kernel_size,\n",
    "                       dil_kernel_size,\n",
    "                       outconv_kernel_size, lr):\n",
    "        self.input_seq_len = input_seq_len\n",
    "        self.c_task_weight = c_task_weight\n",
    "        self.filters = filters\n",
    "        self.n_dil_layers = n_dil_layers\n",
    "        self.conv1_kernel_size = conv1_kernel_size\n",
    "        self.dil_kernel_size = dil_kernel_size\n",
    "        self.outconv_kernel_size = outconv_kernel_size\n",
    "        self.lr = lr\n",
    "\n",
    "    def get_embedding_len(self):\n",
    "        embedding_len = self.input_seq_len\n",
    "        embedding_len -= (self.conv1_kernel_size-1)     \n",
    "        for i in range(1, self.n_dil_layers+1):\n",
    "            dilation_rate = (2**i)\n",
    "            embedding_len -= dilation_rate*(self.dil_kernel_size-1)\n",
    "        return embedding_len\n",
    "\n",
    "    def get_output_profile_len(self):\n",
    "        embedding_len = self.get_embedding_len()\n",
    "        out_profile_len = embedding_len - (self.outconv_kernel_size - 1)\n",
    "        return out_profile_len\n",
    "\n",
    "    def get_keras_model(self):\n",
    "\n",
    "        out_pred_len = self.get_output_profile_len()\n",
    "\n",
    "        inp = kl.Input(shape=(self.input_seq_len, 4), name='sequence')\n",
    "        first_conv = RevCompConv1D(filters=self.filters,\n",
    "                               kernel_size=self.conv1_kernel_size,\n",
    "                               padding='valid',\n",
    "                               activation='relu')(inp)\n",
    "        curr_layer_size = self.input_seq_len - (self.conv1_kernel_size-1)\n",
    "        bias_counts_input = kl.Input(shape=(1,), name=\"control_logcount\")\n",
    "        bias_profile_input = kl.Input(shape=(out_pred_len, 2),\n",
    "                                      name=\"control_profile\")\n",
    "        prev_layers = [first_conv]\n",
    "        for i in range(1, self.n_dil_layers + 1):\n",
    "          dilation_rate = 2**i\n",
    "          if i == 1:\n",
    "              prev_sum = first_conv\n",
    "          else:\n",
    "              print(prev_layers)\n",
    "              prev_sum = kl.merge.Average()(prev_layers)\n",
    "          conv_output = RevCompConv1D(filters=self.filters,\n",
    "                                  kernel_size=self.dil_kernel_size,\n",
    "                                  padding='valid',\n",
    "                                  activation='relu',\n",
    "                                  dilation_rate=dilation_rate)(prev_sum)          \n",
    "          width_to_trim = dilation_rate*(self.dil_kernel_size-1)\n",
    "          curr_layer_size = (curr_layer_size - width_to_trim)\n",
    "          prev_layers = [trim_flanks_of_conv_layer(\n",
    "              conv_layer=x, output_len=curr_layer_size,\n",
    "              width_to_trim=width_to_trim, filters=2*self.filters)\n",
    "              for x in prev_layers]\n",
    "          prev_layers.append(conv_output)\n",
    "\n",
    "        combined_conv = kl.merge.Average()(prev_layers)\n",
    "\n",
    "        #Counts prediction\n",
    "        gap_combined_conv = kl.GlobalAvgPool1D()(combined_conv)\n",
    "        count_out = kl.Reshape((-1,), name=\"task0_logcount\")(\n",
    "            RevCompConv1D(filters=1, kernel_size=1)(\n",
    "              kl.Reshape((1,-1))(kl.concatenate([\n",
    "                  #concatenation of the bias layer both before and after\n",
    "                  # is needed for rc symmetry\n",
    "                  kl.Lambda(lambda x: x[:, ::-1])(bias_counts_input),\n",
    "                  gap_combined_conv,\n",
    "                  bias_counts_input], axis=-1))))\n",
    "\n",
    "        profile_out_prebias = RevCompConv1D(\n",
    "                               filters=1,\n",
    "                               kernel_size=self.outconv_kernel_size,\n",
    "                               padding='valid')(combined_conv)\n",
    "        profile_out = RevCompConv1D(\n",
    "            filters=1, kernel_size=1, name=\"task0_profile\")(\n",
    "                    kl.concatenate([\n",
    "                        #concatenation of the bias layer both before and after\n",
    "                        # is needed for rc symmetry\n",
    "                        kl.Lambda(lambda x: x[:, :, ::-1])(bias_profile_input),\n",
    "                        profile_out_prebias,\n",
    "                        bias_profile_input], axis=-1))\n",
    "\n",
    "        model = keras.models.Model(\n",
    "          inputs=[inp, bias_counts_input, bias_profile_input],\n",
    "          outputs=[count_out, profile_out])\n",
    "        model.compile(keras.optimizers.Adam(lr=self.lr),\n",
    "                      loss=['mse', MultichannelMultinomialNLL(2)],\n",
    "                      loss_weights=[self.c_task_weight, 1])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 546\n",
    "modelwrapper = RcBPnetArch(\n",
    "    input_seq_len=seq_len,\n",
    "    c_task_weight=1000,\n",
    "    filters=100,\n",
    "    n_dil_layers=6,\n",
    "    conv1_kernel_size=21,\n",
    "    dil_kernel_size=3,\n",
    "    outconv_kernel_size=25,\n",
    "    lr=0.001)\n",
    "out_pred_len = modelwrapper.get_output_profile_len()\n",
    "print(out_pred_len, seq_len-out_pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_smooth_log_counts =\\\n",
    "  coordstovals.bigwig.PosAndNegSmoothWindowCollapsedLogCounts(\n",
    "        pos_strand_bigwig_path=\"/users/amr1/pho4/data/ctl_chipexo/chipexo.pos_strand.bw\",\n",
    "        neg_strand_bigwig_path=\"/users/amr1/pho4/data/ctl_chipexo/chipexo.neg_strand.bw\",\n",
    "        counts_mode_name=\"control_logcount\",\n",
    "        profile_mode_name=\"control_profile\",\n",
    "        center_size_to_use=out_pred_len,\n",
    "        smoothing_windows=[1,50])\n",
    "inputs_coordstovals = coordstovals.core.CoordsToValsJoiner(\n",
    "    coordstovals_list=[\n",
    "      coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
    "        genome_fasta_path=\"/users/amr1/pho4/data/genome/sacCer3.genome.fa\",\n",
    "        mode_name=\"sequence\",\n",
    "        center_size_to_use=seq_len),\n",
    "      pos_neg_smooth_log_counts])\n",
    "\n",
    "targets_coordstovals = coordstovals.bigwig.PosAndNegSeparateLogCounts(\n",
    "    pos_strand_bigwig_path=\"/users/amr1/pho4/data/limited_conditions/tye7_glu/tye7.glu.pos.bigwig\",\n",
    "    neg_strand_bigwig_path=\"/users/amr1/pho4/data/limited_conditions/tye7_glu/tye7.glu.neg.bigwig\",\n",
    "    counts_mode_name=\"task0_logcount\",\n",
    "    profile_mode_name=\"task0_profile\",\n",
    "    center_size_to_use=out_pred_len)\n",
    "\n",
    "keras_train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"/users/amr1/pho4/data/limited_conditions/tye7_glu/train_1000_around_summits.bed.gz\",\n",
    "      coord_batch_transformer=\n",
    "          coordbatchtransformers.ReverseComplementAugmenter().chain(\n",
    "          coordbatchtransformers.UniformJitter(\n",
    "              maxshift=200, chromsizes_file=\"/users/amr1/pho4/data/genome/sacCer3.chrom.sizes\")),\n",
    "      batch_size=64,\n",
    "      shuffle_before_epoch=True, \n",
    "      seed=1234),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals)\n",
    "\n",
    "keras_valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "            bed_file=\"/users/amr1/pho4/data/limited_conditions/tye7_glu/valid_1000_around_summits.bed.gz\",\n",
    "            batch_size=64,\n",
    "            shuffle_before_epoch=False, \n",
    "            seed=1234),\n",
    "  inputs_coordstovals=inputs_coordstovals,\n",
    "  targets_coordstovals=targets_coordstovals)\n",
    "\n",
    "thebatch = keras_train_batch_generator[0]\n",
    "for tupleidx,tupleentry in enumerate(thebatch):\n",
    "  print(\"Tuple entry\",tupleidx)\n",
    "  for key in tupleentry:\n",
    "    print(key, tupleentry[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5,6,7\"\n",
    "\n",
    "model = modelwrapper.get_keras_model()\n",
    "print(model.summary())\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                          patience=25, restore_best_weights=True)\n",
    "loss_history = model.fit_generator(keras_train_batch_generator,\n",
    "                  epochs=500,\n",
    "                  validation_data=keras_valid_batch_generator,\n",
    "                  callbacks=[early_stopping_callback])\n",
    "model.set_weights(early_stopping_callback.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/users/amr1/pho4/data/models/tye7_limited_glu_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'MultichannelMultinomialNLL': MultichannelMultinomialNLL,'RevCompConv1D': RevCompConv1D}):\n",
    "    model = load_model('/users/amr1/pho4/data/models/tye7_limited_glu_model.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_test_preds_logcount = []\n",
    "o_test_biastrack_logcount = []\n",
    "o_test_biastrack_profile = []\n",
    "o_test_seqs = []\n",
    "o_test_preds_profile = []\n",
    "o_test_labels_logcount = []\n",
    "o_test_labels_profile = []\n",
    "\n",
    "keras_test_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "            bed_file=\"/users/amr1/pho4/data/limited_conditions/tye7_glu/test_1000_around_summits.bed.gz\",\n",
    "            batch_size=64,\n",
    "            shuffle_before_epoch=False, \n",
    "            seed=1234),\n",
    "  inputs_coordstovals=inputs_coordstovals,\n",
    "  targets_coordstovals=targets_coordstovals)\n",
    "\n",
    "orig_seqs = []\n",
    "\n",
    "for batch_idx in range(len(keras_test_batch_generator)):\n",
    "    batch_inputs, batch_labels = keras_test_batch_generator[batch_idx]\n",
    "    o_test_seqs.append(batch_inputs['sequence']) \n",
    "    o_test_biastrack_logcount.append(batch_inputs['control_logcount'])\n",
    "    o_test_biastrack_profile.append(batch_inputs['control_profile'])    \n",
    "    test_preds = model.predict(batch_inputs)\n",
    "    o_test_preds_logcount.append(test_preds[0])\n",
    "    o_test_preds_profile.append(test_preds[1])\n",
    "    o_test_labels_logcount.append(batch_labels['task0_logcount'])\n",
    "    o_test_labels_profile.append(batch_labels['task0_profile'])\n",
    "o_test_biastrack_logcount = np.concatenate(o_test_biastrack_logcount, axis=0)\n",
    "o_test_biastrack_profile = np.concatenate(o_test_biastrack_profile,axis=0)\n",
    "o_test_seqs = np.concatenate(o_test_seqs,axis=0)\n",
    "o_test_preds_logcount = np.concatenate(o_test_preds_logcount, axis=0)\n",
    "o_test_preds_profile = np.concatenate(o_test_preds_profile, axis=0)\n",
    "o_test_labels_logcount = np.concatenate(o_test_labels_logcount, axis=0)\n",
    "o_test_labels_profile = np.concatenate(o_test_labels_profile, axis=0)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "o_test_labels_logtotalcount = np.log(np.sum(np.exp(o_test_labels_logcount) - 1,axis=-1) + 1)\n",
    "\n",
    "plt.scatter(o_test_biastrack_logcount, o_test_labels_logtotalcount, alpha=0.1)\n",
    "plt.xlabel(\"Bias track log counts\")\n",
    "plt.ylabel(\"True log total counts\")\n",
    "plt.plot([np.min(o_test_biastrack_logcount), np.max(o_test_biastrack_logcount)],\n",
    "         [np.min(o_test_biastrack_logcount), np.max(o_test_biastrack_logcount)],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_test_biastrack_logcount, o_test_labels_logtotalcount))\n",
    "\n",
    "\n",
    "#do a scatterplot of total count predictions\n",
    "plt.scatter(o_test_preds_logcount[:,0], o_test_labels_logcount[:,0], alpha=0.1)\n",
    "plt.xlabel(\"Predicted log counts - Forward Strand\")\n",
    "plt.ylabel(\"True log counts - Forward Strand\")\n",
    "plt.plot([np.min(o_test_preds_logcount[:,0]), np.max(o_test_preds_logcount[:,0])],\n",
    "         [np.min(o_test_preds_logcount[:,0]), np.max(o_test_preds_logcount[:,0])],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_test_preds_logcount[:,0], o_test_labels_logcount[:,0]))\n",
    "\n",
    "plt.scatter(o_test_preds_logcount[:,1], o_test_labels_logcount[:,1], alpha=0.1)\n",
    "plt.xlabel(\"Predicted log counts - Reverse Strand\")\n",
    "plt.ylabel(\"True log counts - Reverse Strand\")\n",
    "plt.plot([np.min(o_test_preds_logcount[:,1]), np.max(o_test_preds_logcount[:,1])],\n",
    "         [np.min(o_test_preds_logcount[:,1]), np.max(o_test_preds_logcount[:,1])],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_test_preds_logcount[:,1], o_test_labels_logcount[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "o_train_preds_logcount = []\n",
    "o_train_biastrack_logcount = []\n",
    "o_train_biastrack_profile = []\n",
    "o_train_seqs = []\n",
    "o_train_preds_profile = []\n",
    "o_train_labels_logcount = []\n",
    "o_train_labels_profile = []\n",
    "\n",
    "orig_seqs = []\n",
    "\n",
    "for batch_idx in range(len(keras_train_batch_generator)):\n",
    "    batch_inputs, batch_labels = keras_train_batch_generator[batch_idx]\n",
    "    o_train_seqs.append(batch_inputs['sequence']) \n",
    "    o_train_biastrack_logcount.append(batch_inputs['control_logcount'])\n",
    "    o_train_biastrack_profile.append(batch_inputs['control_profile'])    \n",
    "    train_preds = model.predict(batch_inputs)\n",
    "    o_train_preds_logcount.append(train_preds[0])\n",
    "    o_train_preds_profile.append(train_preds[1])\n",
    "    o_train_labels_logcount.append(batch_labels['task0_logcount'])\n",
    "    o_train_labels_profile.append(batch_labels['task0_profile'])\n",
    "o_train_biastrack_logcount = np.concatenate(o_train_biastrack_logcount, axis=0)\n",
    "o_train_biastrack_profile = np.concatenate(o_train_biastrack_profile,axis=0)\n",
    "o_train_seqs = np.concatenate(o_train_seqs,axis=0)\n",
    "o_train_preds_logcount = np.concatenate(o_train_preds_logcount, axis=0)\n",
    "o_train_preds_profile = np.concatenate(o_train_preds_profile, axis=0)\n",
    "o_train_labels_logcount = np.concatenate(o_train_labels_logcount, axis=0)\n",
    "o_train_labels_profile = np.concatenate(o_train_labels_profile, axis=0)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "o_train_labels_logtotalcount = np.log(np.sum(np.exp(o_train_labels_logcount) - 1,axis=-1) + 1)\n",
    "\n",
    "plt.scatter(o_train_biastrack_logcount, o_train_labels_logtotalcount, alpha=0.1)\n",
    "plt.xlabel(\"Bias track log counts\")\n",
    "plt.ylabel(\"True log total counts\")\n",
    "plt.plot([np.min(o_train_biastrack_logcount), np.max(o_train_biastrack_logcount)],\n",
    "         [np.min(o_train_biastrack_logcount), np.max(o_train_biastrack_logcount)],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_train_biastrack_logcount, o_train_labels_logtotalcount))\n",
    "\n",
    "\n",
    "#do a scatterplot of total count predictions\n",
    "plt.scatter(o_train_preds_logcount[:,0], o_train_labels_logcount[:,0], alpha=0.1)\n",
    "plt.xlabel(\"Predicted log counts - Forward Strand\")\n",
    "plt.ylabel(\"True log counts - Forward Strand\")\n",
    "plt.plot([np.min(o_train_preds_logcount[:,0]), np.max(o_train_preds_logcount[:,0])],\n",
    "         [np.min(o_train_preds_logcount[:,0]), np.max(o_train_preds_logcount[:,0])],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_train_preds_logcount[:,0], o_train_labels_logcount[:,0]))\n",
    "\n",
    "plt.scatter(o_train_preds_logcount[:,1], o_train_labels_logcount[:,1], alpha=0.1)\n",
    "plt.xlabel(\"Predicted log counts - Reverse Strand\")\n",
    "plt.ylabel(\"True log counts - Reverse Strand\")\n",
    "plt.plot([np.min(o_train_preds_logcount[:,1]), np.max(o_train_preds_logcount[:,1])],\n",
    "         [np.min(o_train_preds_logcount[:,1]), np.max(o_train_preds_logcount[:,1])],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_train_preds_logcount[:,1], o_train_labels_logcount[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from deeplift.dinuc_shuffle import dinuc_shuffle\n",
    "\n",
    "def combine_mult_and_diffref(mult, orig_inp, bg_data):\n",
    "    to_return = []\n",
    "    for l in [0]:\n",
    "        projected_hypothetical_contribs = np.zeros_like(bg_data[l]).astype(\"float\")\n",
    "        assert len(orig_inp[l].shape)==2\n",
    "        #At each position in the input sequence, we iterate over the one-hot encoding\n",
    "        # possibilities (eg: for genomic sequence, this is ACGT i.e.\n",
    "        # 1000, 0100, 0010 and 0001) and compute the hypothetical \n",
    "        # difference-from-reference in each case. We then multiply the hypothetical\n",
    "        # differences-from-reference with the multipliers to get the hypothetical contributions.\n",
    "        #For each of the one-hot encoding possibilities,\n",
    "        # the hypothetical contributions are then summed across the ACGT axis to estimate\n",
    "        # the total hypothetical contribution of each position. This per-position hypothetical\n",
    "        # contribution is then assigned (\"projected\") onto whichever base was present in the\n",
    "        # hypothetical sequence.\n",
    "        #The reason this is a fast estimate of what the importance scores *would* look\n",
    "        # like if different bases were present in the underlying sequence is that\n",
    "        # the multipliers are computed once using the original sequence, and are not\n",
    "        # computed again for each hypothetical sequence.\n",
    "        for i in range(orig_inp[l].shape[-1]):\n",
    "            hypothetical_input = np.zeros_like(orig_inp[l]).astype(\"float\")\n",
    "            hypothetical_input[:,i] = 1.0\n",
    "            hypothetical_difference_from_reference = (hypothetical_input[None,:,:]-bg_data[l])\n",
    "            hypothetical_contribs = hypothetical_difference_from_reference*mult[l]\n",
    "            projected_hypothetical_contribs[:,:,i] = np.sum(hypothetical_contribs,axis=-1) \n",
    "        to_return.append(np.mean(projected_hypothetical_contribs,axis=0))\n",
    "    to_return.append(np.zeros_like(orig_inp[1]))\n",
    "    return to_return\n",
    "\n",
    "def shuffle_several_times(s):\n",
    "    numshuffles=20\n",
    "    return [np.array([dinuc_shuffle(s[0]) for i in range(numshuffles)]),\n",
    "            np.array([s[1] for i in range(numshuffles)])]\n",
    "\n",
    "profile_model_counts_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "    ([model.input[0], model.input[1]],\n",
    "     tf.reduce_sum(model.outputs[0],axis=-1)),\n",
    "    shuffle_several_times,\n",
    "    combine_mult_and_diffref=combine_mult_and_diffref)\n",
    "\n",
    "#See Google slide deck for explanations\n",
    "#We meannorm as per section titled \"Adjustments for Softmax Layers\"\n",
    "# in the DeepLIFT paper\n",
    "meannormed_logits = (\n",
    "    model.outputs[1]-\n",
    "    tf.reduce_mean(model.outputs[1],axis=1)[:,None,:])\n",
    "#'stop_gradient' will prevent importance from being propagated through\n",
    "# this operation; we do this because we just want to treat the post-softmax\n",
    "# probabilities as 'weights' on the different logits, without having the\n",
    "# network explain how the probabilities themselves were derived\n",
    "#Could be worth contrasting explanations derived with and without stop_gradient\n",
    "# enabled...\n",
    "stopgrad_meannormed_logits = tf.stop_gradient(meannormed_logits)\n",
    "softmax_out = tf.nn.softmax(stopgrad_meannormed_logits,axis=1)\n",
    "#Weight the logits according to the softmax probabilities, take the sum for each\n",
    "# example. This mirrors what was done for the bpnet paper.\n",
    "weightedsum_meannormed_logits = tf.reduce_sum(softmax_out*meannormed_logits,\n",
    "                                              axis=(1,2))\n",
    "profile_model_profile_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "    ([model.input[0], model.input[2]],\n",
    "     weightedsum_meannormed_logits),\n",
    "    shuffle_several_times,\n",
    "    combine_mult_and_diffref=combine_mult_and_diffref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The shap scores\n",
    "post_counts_hypimps,_ = profile_model_counts_explainer.shap_values(\n",
    "    [o_test_seqs, np.zeros((len(o_test_seqs), 1))],\n",
    "    progress_message=10)\n",
    "post_profile_hypimps,_ = profile_model_profile_explainer.shap_values(\n",
    "    [o_test_seqs, np.zeros((len(o_test_seqs), out_pred_len, 2))],\n",
    "    progress_message=10)\n",
    "\n",
    "post_counts_actualimps = post_counts_hypimps*o_test_seqs\n",
    "post_profile_actualimps = post_profile_hypimps*o_test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplift.visualization import viz_sequence\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "sorted_test_indices = [x[0] for x in \n",
    "                       sorted(enumerate(o_test_labels_logtotalcount),\n",
    "                              key=lambda x: -x[1])]\n",
    "\n",
    "def smooth(vals):\n",
    "    return np.convolve(vals, np.ones(1,)/1, mode='same')\n",
    "\n",
    "for idx in sorted_test_indices[:10]: \n",
    "    true_profile = o_test_labels_profile[idx] \n",
    "    print(\"idx\",idx)\n",
    "    print(\"Counts\",np.sum(true_profile,axis=0))\n",
    "    print(\"Predcounts\",np.exp(o_test_preds_logcount[idx])-1)\n",
    "    \n",
    "    for oneovertemp in [1.0]:\n",
    "        print(\"oneovertemp\",oneovertemp)\n",
    "        print(o_test_labels_profile[idx].shape)\n",
    "        print(\"Pred profile shape\", o_test_preds_profile[idx].shape)\n",
    "        pred_profile = (np.sum(o_test_labels_profile[idx], axis=0)[None,:] #total counts\n",
    "                      *(np.exp(o_test_preds_profile[idx]*oneovertemp)/\n",
    "                        np.sum(np.exp(o_test_preds_profile[idx]*oneovertemp),axis=0)[None,:]) )   \n",
    "        plt.figure(figsize=(20,2))\n",
    "\n",
    "        start_view = 0\n",
    "        end_view = seq_len\n",
    "        total_flanking = seq_len - out_pred_len\n",
    "        left_flank = int(0.5*total_flanking)\n",
    "        right_flank = total_flanking - left_flank\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, smooth(true_profile[:,0]), alpha=0.3)\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, -smooth(true_profile[:,1]), alpha=0.3)\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, pred_profile[:,0])\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, -pred_profile[:,1])\n",
    "        plt.xlim(start_view,end_view)\n",
    "        plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "        plt.show()\n",
    "\n",
    "    print(\"counts imp\")\n",
    "    viz_sequence.plot_weights(post_counts_actualimps[idx][start_view:end_view],\n",
    "                            subticks_frequency=10)\n",
    "    print(\"profile imp\")\n",
    "    viz_sequence.plot_weights(post_profile_actualimps[idx][start_view:end_view],\n",
    "                            subticks_frequency=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in sorted_test_indices[:10]: \n",
    "    true_profile = o_test_labels_profile[idx] \n",
    "    print(\"idx\",idx)\n",
    "    print(\"Counts\",np.sum(true_profile,axis=0))\n",
    "    print(\"Predcounts\",np.exp(o_test_preds_logcount[idx])-1)\n",
    "    \n",
    "    for oneovertemp in [1.0]:\n",
    "        print(\"oneovertemp\",oneovertemp)\n",
    "        print(o_test_labels_profile[idx].shape)\n",
    "        print(\"Pred profile shape\", o_test_preds_profile[idx].shape)\n",
    "        pred_profile = (np.sum(o_test_labels_profile[idx], axis=0)[None,:] #total counts\n",
    "                      *(np.exp(o_test_preds_profile[idx]*oneovertemp)/\n",
    "                        np.sum(np.exp(o_test_preds_profile[idx]*oneovertemp),axis=0)[None,:]) )   \n",
    "        plt.figure(figsize=(20,2))\n",
    "\n",
    "        start_view = 220\n",
    "        end_view = 325\n",
    "        total_flanking = seq_len - out_pred_len\n",
    "        left_flank = int(0.5*total_flanking)\n",
    "        right_flank = total_flanking - left_flank\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, smooth(true_profile[:,0]), alpha=0.3)\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, -smooth(true_profile[:,1]), alpha=0.3)\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, pred_profile[:,0])\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, -pred_profile[:,1])\n",
    "        plt.xlim(start_view,end_view)\n",
    "        plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "        plt.show()\n",
    "\n",
    "    print(\"counts imp\")\n",
    "    viz_sequence.plot_weights(post_counts_actualimps[idx][start_view:end_view],\n",
    "                            subticks_frequency=10)\n",
    "    print(\"profile imp\")\n",
    "    viz_sequence.plot_weights(post_profile_actualimps[idx][start_view:end_view],\n",
    "                            subticks_frequency=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basepair]",
   "language": "python",
   "name": "conda-env-basepair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
