{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from seqdataloader.batchproducers import coordbased\n",
    "from seqdataloader.batchproducers.coordbased import coordstovals\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchproducers\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchtransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import keras_genomics\n",
    "from keras_genomics.layers.convolutional import RevCompConv1D\n",
    "import keras\n",
    "import keras.layers as kl\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from seqdataloader.batchproducers import coordbased\n",
    "from seqdataloader.batchproducers.coordbased import coordstovals\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchproducers\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchtransformers\n",
    "\n",
    "def multinomial_nll(true_counts, logits):\n",
    "    \"\"\"Compute the multinomial negative log-likelihood\n",
    "    Args:\n",
    "      true_counts: observed count values\n",
    "      logits: predicted logit values\n",
    "    \"\"\"\n",
    "    counts_per_example = tf.reduce_sum(true_counts, axis=-1)\n",
    "    dist = tfp.distributions.Multinomial(total_count=counts_per_example,\n",
    "                                         logits=logits)\n",
    "    return (-tf.reduce_sum(dist.log_prob(true_counts)) / \n",
    "            tf.to_float(tf.shape(true_counts)[0]))\n",
    "\n",
    "\n",
    "#from https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/basepair/losses.py#L87\n",
    "class MultichannelMultinomialNLL(object):\n",
    "    def __init__(self, n):\n",
    "        self.__name__ = \"MultichannelMultinomialNLL\"\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, true_counts, logits):\n",
    "        for i in range(self.n):\n",
    "            loss = multinomial_nll(true_counts[..., i], logits[..., i])\n",
    "            if i == 0:\n",
    "                total = loss\n",
    "            else:\n",
    "                total += loss\n",
    "        return total\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"n\": self.n}\n",
    "\n",
    "#If we want to avoid zero-padding, then the input seq len will be determined\n",
    "# by parameters of the convolutions\n",
    "class AbstractProfileModel(object):\n",
    "\n",
    "    def get_output_profile_len(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_model(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "def trim_flanks_of_conv_layer(conv_layer, output_len, width_to_trim, filters):\n",
    "    layer = keras.layers.Lambda(\n",
    "        lambda x: x[:,\n",
    "          int(0.5*(width_to_trim)):-(width_to_trim-int(0.5*(width_to_trim)))],\n",
    "        output_shape=(output_len, filters))(conv_layer)\n",
    "    return layer\n",
    "\n",
    "#model architecture is based on \n",
    "#https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/basepair/models.py#L534\n",
    "#The non-cli parameters are specified in:\n",
    "# https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/src/chipnexus/train/seqmodel/joint-model-valid.gin\n",
    "#The cli parameters are in line 165 of:\n",
    "# https://docs.google.com/spreadsheets/d/1n3l2HXKSNpmNUOifD41uRzDEAgmOqXMQDxquRaz6WLg/edit#gid=0\n",
    "# which seems to match https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/src/chipnexus/train/seqmodel/ChIP-seq-default.gin\n",
    "class RcBPnetArch(AbstractProfileModel):   \n",
    "\n",
    "    def __init__(self, input_seq_len, c_task_weight, filters,\n",
    "                       n_dil_layers, conv1_kernel_size,\n",
    "                       dil_kernel_size,\n",
    "                       outconv_kernel_size, lr):\n",
    "        self.input_seq_len = input_seq_len\n",
    "        self.c_task_weight = c_task_weight\n",
    "        self.filters = filters\n",
    "        self.n_dil_layers = n_dil_layers\n",
    "        self.conv1_kernel_size = conv1_kernel_size\n",
    "        self.dil_kernel_size = dil_kernel_size\n",
    "        self.outconv_kernel_size = outconv_kernel_size\n",
    "        self.lr = lr\n",
    "\n",
    "    def get_embedding_len(self):\n",
    "        embedding_len = self.input_seq_len\n",
    "        embedding_len -= (self.conv1_kernel_size-1)     \n",
    "        for i in range(1, self.n_dil_layers+1):\n",
    "            dilation_rate = (2**i)\n",
    "            embedding_len -= dilation_rate*(self.dil_kernel_size-1)\n",
    "        return embedding_len\n",
    "\n",
    "    def get_output_profile_len(self):\n",
    "        embedding_len = self.get_embedding_len()\n",
    "        out_profile_len = embedding_len - (self.outconv_kernel_size - 1)\n",
    "        return out_profile_len\n",
    "\n",
    "    def get_keras_model(self):\n",
    "\n",
    "        out_pred_len = self.get_output_profile_len()\n",
    "\n",
    "        inp = kl.Input(shape=(self.input_seq_len, 4), name='sequence')\n",
    "        first_conv = RevCompConv1D(filters=self.filters,\n",
    "                               kernel_size=self.conv1_kernel_size,\n",
    "                               padding='valid',\n",
    "                               activation='relu')(inp)\n",
    "        curr_layer_size = self.input_seq_len - (self.conv1_kernel_size-1)\n",
    "        bias_counts_input = kl.Input(shape=(1,), name=\"control_logcount\")\n",
    "        bias_profile_input = kl.Input(shape=(out_pred_len, 2),\n",
    "                                      name=\"control_profile\")\n",
    "        prev_layers = [first_conv]\n",
    "        for i in range(1, self.n_dil_layers + 1):\n",
    "          dilation_rate = 2**i\n",
    "          if i == 1:\n",
    "              prev_sum = first_conv\n",
    "          else:\n",
    "              print(prev_layers)\n",
    "              prev_sum = kl.merge.Average()(prev_layers)\n",
    "          conv_output = RevCompConv1D(filters=self.filters,\n",
    "                                  kernel_size=self.dil_kernel_size,\n",
    "                                  padding='valid',\n",
    "                                  activation='relu',\n",
    "                                  dilation_rate=dilation_rate)(prev_sum)          \n",
    "          width_to_trim = dilation_rate*(self.dil_kernel_size-1)\n",
    "          curr_layer_size = (curr_layer_size - width_to_trim)\n",
    "          prev_layers = [trim_flanks_of_conv_layer(\n",
    "              conv_layer=x, output_len=curr_layer_size,\n",
    "              width_to_trim=width_to_trim, filters=2*self.filters)\n",
    "              for x in prev_layers]\n",
    "          prev_layers.append(conv_output)\n",
    "\n",
    "        combined_conv = kl.merge.Average()(prev_layers)\n",
    "\n",
    "        #Counts prediction\n",
    "        gap_combined_conv = kl.GlobalAvgPool1D()(combined_conv)\n",
    "        count_out = kl.Reshape((-1,), name=\"task0_logcount\")(\n",
    "            RevCompConv1D(filters=1, kernel_size=1)(\n",
    "              kl.Reshape((1,-1))(kl.concatenate([\n",
    "                  #concatenation of the bias layer both before and after\n",
    "                  # is needed for rc symmetry\n",
    "                  kl.Lambda(lambda x: x[:, ::-1])(bias_counts_input),\n",
    "                  gap_combined_conv,\n",
    "                  bias_counts_input], axis=-1))))\n",
    "\n",
    "        profile_out_prebias = RevCompConv1D(\n",
    "                               filters=1,\n",
    "                               kernel_size=self.outconv_kernel_size,\n",
    "                               padding='valid')(combined_conv)\n",
    "        profile_out = RevCompConv1D(\n",
    "            filters=1, kernel_size=1, name=\"task0_profile\")(\n",
    "                    kl.concatenate([\n",
    "                        #concatenation of the bias layer both before and after\n",
    "                        # is needed for rc symmetry\n",
    "                        kl.Lambda(lambda x: x[:, :, ::-1])(bias_profile_input),\n",
    "                        profile_out_prebias,\n",
    "                        bias_profile_input], axis=-1))\n",
    "\n",
    "        model = keras.models.Model(\n",
    "          inputs=[inp, bias_counts_input, bias_profile_input],\n",
    "          outputs=[count_out, profile_out])\n",
    "        model.compile(keras.optimizers.Adam(lr=self.lr),\n",
    "                      loss=['mse', MultichannelMultinomialNLL(2)],\n",
    "                      loss_weights=[self.c_task_weight, 1])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 346\n"
     ]
    }
   ],
   "source": [
    "seq_len = 546\n",
    "modelwrapper = RcBPnetArch(\n",
    "    input_seq_len=seq_len,\n",
    "    c_task_weight=250,\n",
    "    filters=64,\n",
    "    n_dil_layers=6,\n",
    "    conv1_kernel_size=21,\n",
    "    dil_kernel_size=3,\n",
    "    outconv_kernel_size=75,\n",
    "    lr=0.001)\n",
    "out_pred_len = modelwrapper.get_output_profile_len()\n",
    "print(out_pred_len, seq_len-out_pred_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
      "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
      "Tuple entry 0\n",
      "sequence (128, 546, 4)\n",
      "control_logcount (128,)\n",
      "control_profile (128, 200, 2)\n",
      "Tuple entry 1\n",
      "task0_logcount (128, 2)\n",
      "task0_profile (128, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "pos_neg_smooth_log_counts =\\\n",
    "  coordstovals.bigwig.PosAndNegSmoothWindowCollapsedLogCounts(\n",
    "        pos_strand_bigwig_path=\"/users/amr1/pho4/data/ctl_chipexo/chipexo.pos_strand.bw\",\n",
    "        neg_strand_bigwig_path=\"/users/amr1/pho4/data/ctl_chipexo/chipexo.neg_strand.bw\",\n",
    "        counts_mode_name=\"control_logcount\",\n",
    "        profile_mode_name=\"control_profile\",\n",
    "        center_size_to_use=out_pred_len,\n",
    "        smoothing_windows=[1,50])\n",
    "inputs_coordstovals = coordstovals.core.CoordsToValsJoiner(\n",
    "    coordstovals_list=[\n",
    "      coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
    "        genome_fasta_path=\"/users/amr1/pho4/data/genome/sacCer3.genome.fa\",\n",
    "        mode_name=\"sequence\",\n",
    "        center_size_to_use=seq_len),\n",
    "      pos_neg_smooth_log_counts])\n",
    "\n",
    "targets_coordstovals = coordstovals.bigwig.PosAndNegSeparateLogCounts(\n",
    "    pos_strand_bigwig_path=\"/users/amr1/pho4/data/limited_conditions/tye7_ana/tye7.ana.pos.bigwig\",\n",
    "    neg_strand_bigwig_path=\"/users/amr1/pho4/data/limited_conditions/tye7_ana/tye7.ana.neg.bigwig\",\n",
    "    counts_mode_name=\"task0_logcount\",\n",
    "    profile_mode_name=\"task0_profile\",\n",
    "    center_size_to_use=out_pred_len)\n",
    "\n",
    "keras_train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "      bed_file=\"/users/amr1/pho4/data/limited_conditions/tye7_ana/train_1000_around_summits.bed.gz\",\n",
    "      coord_batch_transformer=\n",
    "          coordbatchtransformers.ReverseComplementAugmenter().chain(\n",
    "          coordbatchtransformers.UniformJitter(\n",
    "              maxshift=200, chromsizes_file=\"/users/amr1/pho4/data/genome/sacCer3.chrom.sizes\")),\n",
    "      batch_size=64,\n",
    "      shuffle_before_epoch=True, \n",
    "      seed=1234),\n",
    "    inputs_coordstovals=inputs_coordstovals,\n",
    "    targets_coordstovals=targets_coordstovals)\n",
    "\n",
    "keras_valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "            bed_file=\"/users/amr1/pho4/data/limited_conditions/tye7_ana/valid_1000_around_summits.bed.gz\",\n",
    "            batch_size=64,\n",
    "            shuffle_before_epoch=False, \n",
    "            seed=1234),\n",
    "  inputs_coordstovals=inputs_coordstovals,\n",
    "  targets_coordstovals=targets_coordstovals)\n",
    "\n",
    "thebatch = keras_train_batch_generator[0]\n",
    "for tupleidx,tupleentry in enumerate(thebatch):\n",
    "  print(\"Tuple entry\",tupleidx)\n",
    "  for key in tupleentry:\n",
    "    print(key, tupleentry[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "[<tf.Tensor 'lambda_1/strided_slice:0' shape=(?, 522, 128) dtype=float32>, <tf.Tensor 'rev_comp_conv1d_2/Relu:0' shape=(?, 522, 128) dtype=float32>]\n",
      "[<tf.Tensor 'lambda_2/strided_slice:0' shape=(?, 514, 128) dtype=float32>, <tf.Tensor 'lambda_3/strided_slice:0' shape=(?, 514, 128) dtype=float32>, <tf.Tensor 'rev_comp_conv1d_3/Relu:0' shape=(?, 514, 128) dtype=float32>]\n",
      "[<tf.Tensor 'lambda_4/strided_slice:0' shape=(?, 498, 128) dtype=float32>, <tf.Tensor 'lambda_5/strided_slice:0' shape=(?, 498, 128) dtype=float32>, <tf.Tensor 'lambda_6/strided_slice:0' shape=(?, 498, 128) dtype=float32>, <tf.Tensor 'rev_comp_conv1d_4/Relu:0' shape=(?, 498, 128) dtype=float32>]\n",
      "[<tf.Tensor 'lambda_7/strided_slice:0' shape=(?, 466, 128) dtype=float32>, <tf.Tensor 'lambda_8/strided_slice:0' shape=(?, 466, 128) dtype=float32>, <tf.Tensor 'lambda_9/strided_slice:0' shape=(?, 466, 128) dtype=float32>, <tf.Tensor 'lambda_10/strided_slice:0' shape=(?, 466, 128) dtype=float32>, <tf.Tensor 'rev_comp_conv1d_5/Relu:0' shape=(?, 466, 128) dtype=float32>]\n",
      "[<tf.Tensor 'lambda_11/strided_slice:0' shape=(?, 402, 128) dtype=float32>, <tf.Tensor 'lambda_12/strided_slice:0' shape=(?, 402, 128) dtype=float32>, <tf.Tensor 'lambda_13/strided_slice:0' shape=(?, 402, 128) dtype=float32>, <tf.Tensor 'lambda_14/strided_slice:0' shape=(?, 402, 128) dtype=float32>, <tf.Tensor 'lambda_15/strided_slice:0' shape=(?, 402, 128) dtype=float32>, <tf.Tensor 'rev_comp_conv1d_6/Relu:0' shape=(?, 402, 128) dtype=float32>]\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-dbf16efbe78d>:28: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           (None, 546, 4)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_1 (RevCompConv1 (None, 526, 128)     5440        sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 522, 128)     0           rev_comp_conv1d_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_2 (RevCompConv1 (None, 522, 128)     24640       rev_comp_conv1d_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 522, 128)     0           lambda_1[0][0]                   \n",
      "                                                                 rev_comp_conv1d_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 514, 128)     0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 514, 128)     0           rev_comp_conv1d_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_3 (RevCompConv1 (None, 514, 128)     24640       average_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_2 (Average)             (None, 514, 128)     0           lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 rev_comp_conv1d_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 498, 128)     0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 498, 128)     0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 498, 128)     0           rev_comp_conv1d_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_4 (RevCompConv1 (None, 498, 128)     24640       average_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_3 (Average)             (None, 498, 128)     0           lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 rev_comp_conv1d_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 466, 128)     0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 466, 128)     0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 466, 128)     0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 466, 128)     0           rev_comp_conv1d_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_5 (RevCompConv1 (None, 466, 128)     24640       average_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_4 (Average)             (None, 466, 128)     0           lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 rev_comp_conv1d_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 402, 128)     0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 402, 128)     0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 402, 128)     0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 402, 128)     0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 402, 128)     0           rev_comp_conv1d_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_6 (RevCompConv1 (None, 402, 128)     24640       average_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_5 (Average)             (None, 402, 128)     0           lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 rev_comp_conv1d_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 274, 128)     0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 274, 128)     0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 274, 128)     0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 274, 128)     0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 274, 128)     0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 274, 128)     0           rev_comp_conv1d_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_7 (RevCompConv1 (None, 274, 128)     24640       average_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "control_logcount (InputLayer)   (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "average_6 (Average)             (None, 274, 128)     0           lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 rev_comp_conv1d_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1)            0           control_logcount[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           average_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 130)          0           lambda_22[0][0]                  \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 control_logcount[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "control_profile (InputLayer)    (None, 200, 2)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 130)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 200, 2)       0           control_profile[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_9 (RevCompConv1 (None, 200, 2)       9601        average_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rev_comp_conv1d_8 (RevCompConv1 (None, 1, 2)         131         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 200, 6)       0           lambda_23[0][0]                  \n",
      "                                                                 rev_comp_conv1d_9[0][0]          \n",
      "                                                                 control_profile[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "task0_logcount (Reshape)        (None, 2)            0           rev_comp_conv1d_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "task0_profile (RevCompConv1D)   (None, 200, 2)       7           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 163,019\n",
      "Trainable params: 163,019\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/500\n",
      "69/69 [==============================] - 15s 221ms/step - loss: 3031.5968 - task0_logcount_loss: 3.3232 - task0_profile_loss: 2200.8081 - val_loss: 2299.7755 - val_task0_logcount_loss: 2.0237 - val_task0_profile_loss: 1793.8442\n",
      "Epoch 2/500\n",
      "69/69 [==============================] - 10s 149ms/step - loss: 2337.5865 - task0_logcount_loss: 2.9597 - task0_profile_loss: 1597.6696 - val_loss: 1785.5993 - val_task0_logcount_loss: 2.1428 - val_task0_profile_loss: 1249.8905\n",
      "Epoch 3/500\n",
      "69/69 [==============================] - 11s 159ms/step - loss: 1779.5974 - task0_logcount_loss: 2.9382 - task0_profile_loss: 1045.0477 - val_loss: 1387.7100 - val_task0_logcount_loss: 2.1432 - val_task0_profile_loss: 851.9171\n",
      "Epoch 4/500\n",
      "69/69 [==============================] - 10s 151ms/step - loss: 1488.2035 - task0_logcount_loss: 2.9753 - task0_profile_loss: 744.3719 - val_loss: 1337.3775 - val_task0_logcount_loss: 2.4359 - val_task0_profile_loss: 728.3939\n",
      "Epoch 5/500\n",
      "69/69 [==============================] - 11s 156ms/step - loss: 1381.5991 - task0_logcount_loss: 2.9227 - task0_profile_loss: 650.9243 - val_loss: 1267.0089 - val_task0_logcount_loss: 2.2033 - val_task0_profile_loss: 716.1872\n",
      "Epoch 6/500\n",
      "69/69 [==============================] - 11s 158ms/step - loss: 1360.1442 - task0_logcount_loss: 2.9361 - task0_profile_loss: 626.1140 - val_loss: 1273.7377 - val_task0_logcount_loss: 2.2186 - val_task0_profile_loss: 719.0955\n",
      "Epoch 7/500\n",
      "69/69 [==============================] - 11s 154ms/step - loss: 1353.5584 - task0_logcount_loss: 2.9379 - task0_profile_loss: 619.0760 - val_loss: 1206.1261 - val_task0_logcount_loss: 1.9745 - val_task0_profile_loss: 712.4943\n",
      "Epoch 8/500\n",
      "69/69 [==============================] - 11s 161ms/step - loss: 1352.2736 - task0_logcount_loss: 2.9612 - task0_profile_loss: 611.9782 - val_loss: 1251.0841 - val_task0_logcount_loss: 2.1343 - val_task0_profile_loss: 717.5199\n",
      "Epoch 9/500\n",
      "69/69 [==============================] - 11s 162ms/step - loss: 1354.9255 - task0_logcount_loss: 2.9614 - task0_profile_loss: 614.5658 - val_loss: 1286.8337 - val_task0_logcount_loss: 2.2907 - val_task0_profile_loss: 714.1620\n",
      "Epoch 10/500\n",
      "69/69 [==============================] - 11s 164ms/step - loss: 1348.6670 - task0_logcount_loss: 2.9550 - task0_profile_loss: 609.9131 - val_loss: 1227.3660 - val_task0_logcount_loss: 2.0642 - val_task0_profile_loss: 711.3089\n",
      "Epoch 11/500\n",
      "69/69 [==============================] - 11s 161ms/step - loss: 1333.4595 - task0_logcount_loss: 2.9164 - task0_profile_loss: 604.3647 - val_loss: 1267.5841 - val_task0_logcount_loss: 2.2192 - val_task0_profile_loss: 712.7960\n",
      "Epoch 12/500\n",
      "69/69 [==============================] - 11s 162ms/step - loss: 1328.8708 - task0_logcount_loss: 2.8946 - task0_profile_loss: 605.2118 - val_loss: 1213.3964 - val_task0_logcount_loss: 1.9979 - val_task0_profile_loss: 713.9311\n",
      "Epoch 13/500\n",
      "69/69 [==============================] - 11s 164ms/step - loss: 1340.7740 - task0_logcount_loss: 2.9703 - task0_profile_loss: 598.2049 - val_loss: 1239.6804 - val_task0_logcount_loss: 2.0932 - val_task0_profile_loss: 716.3760\n",
      "Epoch 14/500\n",
      "69/69 [==============================] - 11s 162ms/step - loss: 1341.6160 - task0_logcount_loss: 2.9884 - task0_profile_loss: 594.5085 - val_loss: 1231.2623 - val_task0_logcount_loss: 2.0595 - val_task0_profile_loss: 716.3868\n",
      "Epoch 15/500\n",
      "69/69 [==============================] - 11s 156ms/step - loss: 1317.2820 - task0_logcount_loss: 2.9012 - task0_profile_loss: 591.9918 - val_loss: 1246.1308 - val_task0_logcount_loss: 2.0968 - val_task0_profile_loss: 721.9376\n",
      "Epoch 16/500\n",
      "69/69 [==============================] - 11s 161ms/step - loss: 1323.5539 - task0_logcount_loss: 2.9655 - task0_profile_loss: 582.1785 - val_loss: 1254.4870 - val_task0_logcount_loss: 2.1248 - val_task0_profile_loss: 723.2908\n",
      "Epoch 17/500\n",
      "69/69 [==============================] - 11s 166ms/step - loss: 1298.9141 - task0_logcount_loss: 2.8598 - task0_profile_loss: 583.9673 - val_loss: 1289.7797 - val_task0_logcount_loss: 2.2639 - val_task0_profile_loss: 723.8092\n",
      "Epoch 18/500\n",
      "69/69 [==============================] - 11s 164ms/step - loss: 1313.4385 - task0_logcount_loss: 2.9411 - task0_profile_loss: 578.1522 - val_loss: 1245.6665 - val_task0_logcount_loss: 2.0667 - val_task0_profile_loss: 728.9994\n",
      "Epoch 19/500\n",
      "69/69 [==============================] - 11s 154ms/step - loss: 1304.4082 - task0_logcount_loss: 2.9282 - task0_profile_loss: 572.3571 - val_loss: 1227.9616 - val_task0_logcount_loss: 1.9847 - val_task0_profile_loss: 731.7948\n",
      "Epoch 20/500\n",
      "69/69 [==============================] - 11s 163ms/step - loss: 1311.8206 - task0_logcount_loss: 2.9637 - task0_profile_loss: 570.9010 - val_loss: 1231.8417 - val_task0_logcount_loss: 1.9953 - val_task0_profile_loss: 733.0209\n",
      "Epoch 21/500\n",
      "69/69 [==============================] - 11s 162ms/step - loss: 1287.0721 - task0_logcount_loss: 2.8856 - task0_profile_loss: 565.6674 - val_loss: 1339.5534 - val_task0_logcount_loss: 2.4160 - val_task0_profile_loss: 735.5588\n",
      "Epoch 22/500\n",
      "69/69 [==============================] - 11s 155ms/step - loss: 1288.0029 - task0_logcount_loss: 2.8907 - task0_profile_loss: 565.3230 - val_loss: 1309.5556 - val_task0_logcount_loss: 2.2523 - val_task0_profile_loss: 746.4706\n",
      "Epoch 23/500\n",
      "69/69 [==============================] - 11s 162ms/step - loss: 1285.5230 - task0_logcount_loss: 2.9076 - task0_profile_loss: 558.6170 - val_loss: 1285.6913 - val_task0_logcount_loss: 2.1308 - val_task0_profile_loss: 752.9986\n",
      "Epoch 24/500\n",
      "69/69 [==============================] - 11s 162ms/step - loss: 1272.8206 - task0_logcount_loss: 2.8943 - task0_profile_loss: 549.2364 - val_loss: 1291.1462 - val_task0_logcount_loss: 2.1329 - val_task0_profile_loss: 757.9313\n",
      "Epoch 25/500\n",
      "69/69 [==============================] - 11s 163ms/step - loss: 1279.7399 - task0_logcount_loss: 2.9151 - task0_profile_loss: 550.9544 - val_loss: 1268.7970 - val_task0_logcount_loss: 2.0163 - val_task0_profile_loss: 764.7288\n",
      "Epoch 26/500\n",
      "69/69 [==============================] - 11s 159ms/step - loss: 1267.7872 - task0_logcount_loss: 2.9053 - task0_profile_loss: 541.4600 - val_loss: 1323.3620 - val_task0_logcount_loss: 2.2051 - val_task0_profile_loss: 772.0950\n",
      "Epoch 27/500\n",
      "69/69 [==============================] - 11s 161ms/step - loss: 1264.0745 - task0_logcount_loss: 2.8826 - task0_profile_loss: 543.4288 - val_loss: 1303.7714 - val_task0_logcount_loss: 2.1041 - val_task0_profile_loss: 777.7400\n",
      "Epoch 28/500\n",
      "41/69 [================>.............] - ETA: 4s - loss: 1238.8708 - task0_logcount_loss: 2.8413 - task0_profile_loss: 528.5462"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "\n",
    "model = modelwrapper.get_keras_model()\n",
    "print(model.summary())\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                          patience=25, restore_best_weights=True)\n",
    "loss_history = model.fit_generator(keras_train_batch_generator,\n",
    "                  epochs=500,\n",
    "                  validation_data=keras_valid_batch_generator,\n",
    "                  callbacks=[early_stopping_callback])\n",
    "model.set_weights(early_stopping_callback.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/users/amr1/pho4/data/models/tye7_limited_ana_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'MultichannelMultinomialNLL': MultichannelMultinomialNLL,'RevCompConv1D': RevCompConv1D}):\n",
    "    model = load_model('/users/amr1/pho4/data/models/tye7_limited_ana_model.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_test_preds_logcount = []\n",
    "o_test_biastrack_logcount = []\n",
    "o_test_biastrack_profile = []\n",
    "o_test_seqs = []\n",
    "o_test_preds_profile = []\n",
    "o_test_labels_logcount = []\n",
    "o_test_labels_profile = []\n",
    "\n",
    "keras_test_batch_generator = coordbased.core.KerasBatchGenerator(\n",
    "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
    "            bed_file=\"/users/amr1/pho4/data/limited_conditions/tye7_ana/test_1000_around_summits.bed.gz\",\n",
    "            batch_size=64,\n",
    "            shuffle_before_epoch=False, \n",
    "            seed=1234),\n",
    "  inputs_coordstovals=inputs_coordstovals,\n",
    "  targets_coordstovals=targets_coordstovals)\n",
    "\n",
    "orig_seqs = []\n",
    "\n",
    "for batch_idx in range(len(keras_test_batch_generator)):\n",
    "    batch_inputs, batch_labels = keras_test_batch_generator[batch_idx]\n",
    "    o_test_seqs.append(batch_inputs['sequence']) \n",
    "    o_test_biastrack_logcount.append(batch_inputs['control_logcount'])\n",
    "    o_test_biastrack_profile.append(batch_inputs['control_profile'])    \n",
    "    test_preds = model.predict(batch_inputs)\n",
    "    o_test_preds_logcount.append(test_preds[0])\n",
    "    o_test_preds_profile.append(test_preds[1])\n",
    "    o_test_labels_logcount.append(batch_labels['task0_logcount'])\n",
    "    o_test_labels_profile.append(batch_labels['task0_profile'])\n",
    "o_test_biastrack_logcount = np.concatenate(o_test_biastrack_logcount, axis=0)\n",
    "o_test_biastrack_profile = np.concatenate(o_test_biastrack_profile,axis=0)\n",
    "o_test_seqs = np.concatenate(o_test_seqs,axis=0)\n",
    "o_test_preds_logcount = np.concatenate(o_test_preds_logcount, axis=0)\n",
    "o_test_preds_profile = np.concatenate(o_test_preds_profile, axis=0)\n",
    "o_test_labels_logcount = np.concatenate(o_test_labels_logcount, axis=0)\n",
    "o_test_labels_profile = np.concatenate(o_test_labels_profile, axis=0)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "o_test_labels_logtotalcount = np.log(np.sum(np.exp(o_test_labels_logcount) - 1,axis=-1) + 1)\n",
    "\n",
    "plt.scatter(o_test_biastrack_logcount, o_test_labels_logtotalcount, alpha=0.1)\n",
    "plt.xlabel(\"Bias track log counts\")\n",
    "plt.ylabel(\"True log total counts\")\n",
    "plt.plot([np.min(o_test_biastrack_logcount), np.max(o_test_biastrack_logcount)],\n",
    "         [np.min(o_test_biastrack_logcount), np.max(o_test_biastrack_logcount)],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_test_biastrack_logcount, o_test_labels_logtotalcount))\n",
    "\n",
    "\n",
    "#do a scatterplot of total count predictions\n",
    "plt.scatter(o_test_preds_logcount[:,0], o_test_labels_logcount[:,0], alpha=0.1)\n",
    "plt.xlabel(\"Predicted log counts - Forward Strand\")\n",
    "plt.ylabel(\"True log counts - Forward Strand\")\n",
    "plt.plot([np.min(o_test_preds_logcount[:,0]), np.max(o_test_preds_logcount[:,0])],\n",
    "         [np.min(o_test_preds_logcount[:,0]), np.max(o_test_preds_logcount[:,0])],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_test_preds_logcount[:,0], o_test_labels_logcount[:,0]))\n",
    "\n",
    "plt.scatter(o_test_preds_logcount[:,1], o_test_labels_logcount[:,1], alpha=0.1)\n",
    "plt.xlabel(\"Predicted log counts - Reverse Strand\")\n",
    "plt.ylabel(\"True log counts - Reverse Strand\")\n",
    "plt.plot([np.min(o_test_preds_logcount[:,1]), np.max(o_test_preds_logcount[:,1])],\n",
    "         [np.min(o_test_preds_logcount[:,1]), np.max(o_test_preds_logcount[:,1])],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_test_preds_logcount[:,1], o_test_labels_logcount[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "o_train_preds_logcount = []\n",
    "o_train_biastrack_logcount = []\n",
    "o_train_biastrack_profile = []\n",
    "o_train_seqs = []\n",
    "o_train_preds_profile = []\n",
    "o_train_labels_logcount = []\n",
    "o_train_labels_profile = []\n",
    "\n",
    "orig_seqs = []\n",
    "\n",
    "for batch_idx in range(len(keras_train_batch_generator)):\n",
    "    batch_inputs, batch_labels = keras_train_batch_generator[batch_idx]\n",
    "    o_train_seqs.append(batch_inputs['sequence']) \n",
    "    o_train_biastrack_logcount.append(batch_inputs['control_logcount'])\n",
    "    o_train_biastrack_profile.append(batch_inputs['control_profile'])    \n",
    "    train_preds = model.predict(batch_inputs)\n",
    "    o_train_preds_logcount.append(train_preds[0])\n",
    "    o_train_preds_profile.append(train_preds[1])\n",
    "    o_train_labels_logcount.append(batch_labels['task0_logcount'])\n",
    "    o_train_labels_profile.append(batch_labels['task0_profile'])\n",
    "o_train_biastrack_logcount = np.concatenate(o_train_biastrack_logcount, axis=0)\n",
    "o_train_biastrack_profile = np.concatenate(o_train_biastrack_profile,axis=0)\n",
    "o_train_seqs = np.concatenate(o_train_seqs,axis=0)\n",
    "o_train_preds_logcount = np.concatenate(o_train_preds_logcount, axis=0)\n",
    "o_train_preds_profile = np.concatenate(o_train_preds_profile, axis=0)\n",
    "o_train_labels_logcount = np.concatenate(o_train_labels_logcount, axis=0)\n",
    "o_train_labels_profile = np.concatenate(o_train_labels_profile, axis=0)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "o_train_labels_logtotalcount = np.log(np.sum(np.exp(o_train_labels_logcount) - 1,axis=-1) + 1)\n",
    "\n",
    "plt.scatter(o_train_biastrack_logcount, o_train_labels_logtotalcount, alpha=0.1)\n",
    "plt.xlabel(\"Bias track log counts\")\n",
    "plt.ylabel(\"True log total counts\")\n",
    "plt.plot([np.min(o_train_biastrack_logcount), np.max(o_train_biastrack_logcount)],\n",
    "         [np.min(o_train_biastrack_logcount), np.max(o_train_biastrack_logcount)],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_train_biastrack_logcount, o_train_labels_logtotalcount))\n",
    "\n",
    "\n",
    "#do a scatterplot of total count predictions\n",
    "plt.scatter(o_train_preds_logcount[:,0], o_train_labels_logcount[:,0], alpha=0.1)\n",
    "plt.xlabel(\"Predicted log counts - Forward Strand\")\n",
    "plt.ylabel(\"True log counts - Forward Strand\")\n",
    "plt.plot([np.min(o_train_preds_logcount[:,0]), np.max(o_train_preds_logcount[:,0])],\n",
    "         [np.min(o_train_preds_logcount[:,0]), np.max(o_train_preds_logcount[:,0])],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_train_preds_logcount[:,0], o_train_labels_logcount[:,0]))\n",
    "\n",
    "plt.scatter(o_train_preds_logcount[:,1], o_train_labels_logcount[:,1], alpha=0.1)\n",
    "plt.xlabel(\"Predicted log counts - Reverse Strand\")\n",
    "plt.ylabel(\"True log counts - Reverse Strand\")\n",
    "plt.plot([np.min(o_train_preds_logcount[:,1]), np.max(o_train_preds_logcount[:,1])],\n",
    "         [np.min(o_train_preds_logcount[:,1]), np.max(o_train_preds_logcount[:,1])],\n",
    "         color=\"black\")\n",
    "plt.show()\n",
    "print(spearmanr(o_train_preds_logcount[:,1], o_train_labels_logcount[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "from deeplift.dinuc_shuffle import dinuc_shuffle\n",
    "\n",
    "def combine_mult_and_diffref(mult, orig_inp, bg_data):\n",
    "    to_return = []\n",
    "    for l in [0]:\n",
    "        projected_hypothetical_contribs = np.zeros_like(bg_data[l]).astype(\"float\")\n",
    "        assert len(orig_inp[l].shape)==2\n",
    "        #At each position in the input sequence, we iterate over the one-hot encoding\n",
    "        # possibilities (eg: for genomic sequence, this is ACGT i.e.\n",
    "        # 1000, 0100, 0010 and 0001) and compute the hypothetical \n",
    "        # difference-from-reference in each case. We then multiply the hypothetical\n",
    "        # differences-from-reference with the multipliers to get the hypothetical contributions.\n",
    "        #For each of the one-hot encoding possibilities,\n",
    "        # the hypothetical contributions are then summed across the ACGT axis to estimate\n",
    "        # the total hypothetical contribution of each position. This per-position hypothetical\n",
    "        # contribution is then assigned (\"projected\") onto whichever base was present in the\n",
    "        # hypothetical sequence.\n",
    "        #The reason this is a fast estimate of what the importance scores *would* look\n",
    "        # like if different bases were present in the underlying sequence is that\n",
    "        # the multipliers are computed once using the original sequence, and are not\n",
    "        # computed again for each hypothetical sequence.\n",
    "        for i in range(orig_inp[l].shape[-1]):\n",
    "            hypothetical_input = np.zeros_like(orig_inp[l]).astype(\"float\")\n",
    "            hypothetical_input[:,i] = 1.0\n",
    "            hypothetical_difference_from_reference = (hypothetical_input[None,:,:]-bg_data[l])\n",
    "            hypothetical_contribs = hypothetical_difference_from_reference*mult[l]\n",
    "            projected_hypothetical_contribs[:,:,i] = np.sum(hypothetical_contribs,axis=-1) \n",
    "        to_return.append(np.mean(projected_hypothetical_contribs,axis=0))\n",
    "    to_return.append(np.zeros_like(orig_inp[1]))\n",
    "    return to_return\n",
    "\n",
    "def shuffle_several_times(s):\n",
    "    numshuffles=20\n",
    "    return [np.array([dinuc_shuffle(s[0]) for i in range(numshuffles)]),\n",
    "            np.array([s[1] for i in range(numshuffles)])]\n",
    "\n",
    "profile_model_counts_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "    ([model.input[0], model.input[1]],\n",
    "     tf.reduce_sum(model.outputs[0],axis=-1)),\n",
    "    shuffle_several_times,\n",
    "    combine_mult_and_diffref=combine_mult_and_diffref)\n",
    "\n",
    "#See Google slide deck for explanations\n",
    "#We meannorm as per section titled \"Adjustments for Softmax Layers\"\n",
    "# in the DeepLIFT paper\n",
    "meannormed_logits = (\n",
    "    model.outputs[1]-\n",
    "    tf.reduce_mean(model.outputs[1],axis=1)[:,None,:])\n",
    "#'stop_gradient' will prevent importance from being propagated through\n",
    "# this operation; we do this because we just want to treat the post-softmax\n",
    "# probabilities as 'weights' on the different logits, without having the\n",
    "# network explain how the probabilities themselves were derived\n",
    "#Could be worth contrasting explanations derived with and without stop_gradient\n",
    "# enabled...\n",
    "stopgrad_meannormed_logits = tf.stop_gradient(meannormed_logits)\n",
    "softmax_out = tf.nn.softmax(stopgrad_meannormed_logits,axis=1)\n",
    "#Weight the logits according to the softmax probabilities, take the sum for each\n",
    "# example. This mirrors what was done for the bpnet paper.\n",
    "weightedsum_meannormed_logits = tf.reduce_sum(softmax_out*meannormed_logits,\n",
    "                                              axis=(1,2))\n",
    "profile_model_profile_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "    ([model.input[0], model.input[2]],\n",
    "     weightedsum_meannormed_logits),\n",
    "    shuffle_several_times,\n",
    "    combine_mult_and_diffref=combine_mult_and_diffref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The shap scores\n",
    "post_counts_hypimps,_ = profile_model_counts_explainer.shap_values(\n",
    "    [o_test_seqs, np.zeros((len(o_test_seqs), 1))],\n",
    "    progress_message=10)\n",
    "post_profile_hypimps,_ = profile_model_profile_explainer.shap_values(\n",
    "    [o_test_seqs, np.zeros((len(o_test_seqs), out_pred_len, 2))],\n",
    "    progress_message=10)\n",
    "\n",
    "post_counts_actualimps = post_counts_hypimps*o_test_seqs\n",
    "post_profile_actualimps = post_profile_hypimps*o_test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplift.visualization import viz_sequence\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "sorted_test_indices = [x[0] for x in \n",
    "                       sorted(enumerate(o_test_labels_logtotalcount),\n",
    "                              key=lambda x: -x[1])]\n",
    "\n",
    "def smooth(vals):\n",
    "    return np.convolve(vals, np.ones(1,)/1, mode='same')\n",
    "\n",
    "for idx in sorted_test_indices[:10]: \n",
    "    true_profile = o_test_labels_profile[idx] \n",
    "    print(\"idx\",idx)\n",
    "    print(\"Counts\",np.sum(true_profile,axis=0))\n",
    "    print(\"Predcounts\",np.exp(o_test_preds_logcount[idx])-1)\n",
    "    \n",
    "    for oneovertemp in [1.0]:\n",
    "        print(\"oneovertemp\",oneovertemp)\n",
    "        print(o_test_labels_profile[idx].shape)\n",
    "        print(\"Pred profile shape\", o_test_preds_profile[idx].shape)\n",
    "        pred_profile = (np.sum(o_test_labels_profile[idx], axis=0)[None,:] #total counts\n",
    "                      *(np.exp(o_test_preds_profile[idx]*oneovertemp)/\n",
    "                        np.sum(np.exp(o_test_preds_profile[idx]*oneovertemp),axis=0)[None,:]) )   \n",
    "        plt.figure(figsize=(20,2))\n",
    "\n",
    "        start_view = 0\n",
    "        end_view = seq_len\n",
    "        total_flanking = seq_len - out_pred_len\n",
    "        left_flank = int(0.5*total_flanking)\n",
    "        right_flank = total_flanking - left_flank\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, smooth(true_profile[:,0]), alpha=0.3)\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, -smooth(true_profile[:,1]), alpha=0.3)\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, pred_profile[:,0])\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, -pred_profile[:,1])\n",
    "        plt.xlim(start_view,end_view)\n",
    "        plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "        plt.show()\n",
    "\n",
    "    print(\"counts imp\")\n",
    "    viz_sequence.plot_weights(post_counts_actualimps[idx][start_view:end_view],\n",
    "                            subticks_frequency=10)\n",
    "    print(\"profile imp\")\n",
    "    viz_sequence.plot_weights(post_profile_actualimps[idx][start_view:end_view],\n",
    "                            subticks_frequency=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in sorted_test_indices[:10]: \n",
    "    true_profile = o_test_labels_profile[idx] \n",
    "    print(\"idx\",idx)\n",
    "    print(\"Counts\",np.sum(true_profile,axis=0))\n",
    "    print(\"Predcounts\",np.exp(o_test_preds_logcount[idx])-1)\n",
    "    \n",
    "    for oneovertemp in [1.0]:\n",
    "        print(\"oneovertemp\",oneovertemp)\n",
    "        print(o_test_labels_profile[idx].shape)\n",
    "        print(\"Pred profile shape\", o_test_preds_profile[idx].shape)\n",
    "        pred_profile = (np.sum(o_test_labels_profile[idx], axis=0)[None,:] #total counts\n",
    "                      *(np.exp(o_test_preds_profile[idx]*oneovertemp)/\n",
    "                        np.sum(np.exp(o_test_preds_profile[idx]*oneovertemp),axis=0)[None,:]) )   \n",
    "        plt.figure(figsize=(20,2))\n",
    "\n",
    "        start_view = 220\n",
    "        end_view = 325\n",
    "        total_flanking = seq_len - out_pred_len\n",
    "        left_flank = int(0.5*total_flanking)\n",
    "        right_flank = total_flanking - left_flank\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, smooth(true_profile[:,0]), alpha=0.3)\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, -smooth(true_profile[:,1]), alpha=0.3)\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, pred_profile[:,0])\n",
    "        plt.plot(np.arange(out_pred_len)+left_flank, -pred_profile[:,1])\n",
    "        plt.xlim(start_view,end_view)\n",
    "        plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
    "        plt.show()\n",
    "\n",
    "    print(\"counts imp\")\n",
    "    viz_sequence.plot_weights(post_counts_actualimps[idx][start_view:end_view],\n",
    "                            subticks_frequency=10)\n",
    "    print(\"profile imp\")\n",
    "    viz_sequence.plot_weights(post_profile_actualimps[idx][start_view:end_view],\n",
    "                            subticks_frequency=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basepair]",
   "language": "python",
   "name": "conda-env-basepair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
