{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "from numpy import log, exp\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import spearmanr, pearsonr, gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + exp(-x))\n",
    "\n",
    "def logit(p):\n",
    "    return log(p) - log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibratorFactory(object):\n",
    "    def __call__(self, valid_preacts, valid_labels):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class LinearRegression(CalibratorFactory):\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose \n",
    "\n",
    "    def __call__(self, valid_preacts, valid_labels):\n",
    "        lr = LR().fit(valid_preacts.reshape(-1, 1), valid_labels)\n",
    "    \n",
    "        def calibration_func(preact):\n",
    "            return lr.predict(preact.reshape(-1, 1))\n",
    "\n",
    "        return calibration_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibratorFactory(object):\n",
    "    def __call__(self, valid_preacts, valid_labels):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class SigmoidFit(CalibratorFactory):\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, valid_preacts, valid_labels):\n",
    "        def loss_func(x):\n",
    "            new_preacts = (x[0]*sigmoid(-valid_labels+x[1]))+x[2]\n",
    "            return mean_squared_error(new_preacts, valid_preacts)\n",
    "\n",
    "        x0 = np.array([1.0, 0.0, 0.0])\n",
    "        res = None\n",
    "        for c in range(10):\n",
    "            curr = minimize(loss_func, x0, method='BFGS', options={'gtol': 1e-9, 'disp': True, 'maxiter': 1000})\n",
    "            if res == None or curr.fun < res.fun:\n",
    "                res = curr\n",
    "        print(\"multiplier: \",res.x[0],\", in sigmoid bias: \",res.x[1],\", out of sigmoid bias: \",res.x[2])\n",
    "\n",
    "        def calibration_func(label):\n",
    "            return (res.x[0]*sigmoid(-label+res.x[1]))+res.x[2]\n",
    "\n",
    "        def inv_func(preact):\n",
    "            return -logit((preact-res.x[2])/res.x[0])+res.x[1]\n",
    "\n",
    "        return calibration_func, inv_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flankToCbf1Ddg = {}\n",
    "flankToPho4Ddg = {}\n",
    "firstLine = True\n",
    "allFlanks = []\n",
    "with open(\"data/experimental/all_predicted_ddGs.csv\") as inp:\n",
    "    for line in inp:\n",
    "        if firstLine:\n",
    "            firstLine = False\n",
    "            continue\n",
    "        flank, Cbf1_ddg, Pho4_ddg = line.strip().split(',')\n",
    "        flankToCbf1Ddg[flank] = float(Cbf1_ddg)\n",
    "        flankToPho4Ddg[flank] = float(Pho4_ddg)\n",
    "        allFlanks.append(flank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_text1 = codecs.open(\"data/preds/pbexo.pho4.flankToDeltaLogCount.json\", 'r', encoding='utf-8').read()\n",
    "flankToPho4CountPreds = json.loads(obj_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_text2 = codecs.open(\"data/preds/pbexo.cbf1.flankToDeltaLogCount.json\", 'r', encoding='utf-8').read()\n",
    "flankToPBCbf1Preds = json.loads(obj_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_text3 = codecs.open(\"data/preds/limited.cbf1.eth.logCounts_fixed_min.json\", 'r', encoding='utf-8').read()\n",
    "flankToChPCbf1Preds = json.loads(obj_text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_keys = np.random.choice(allFlanks, 110000, replace=False)\n",
    "sampled_valid_keys = sampled_keys[100000:]\n",
    "sampled_keys = sampled_keys[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplePho4CountPreds = {}\n",
    "samplePBCbf1Preds = {}\n",
    "sampleChPCbf1Preds = {}\n",
    "samplePho4LogCountPreds = {}\n",
    "samplePBCbf1LogPreds = {}\n",
    "sampleChPCbf1LogPreds = {}\n",
    "for key in sampled_keys:\n",
    "    y_0 = np.array(flankToPho4CountPreds[key][0]).astype(float)\n",
    "    y_1 = np.array(flankToPho4CountPreds[key][1]).astype(float)\n",
    "    samplePho4LogCountPreds[key] = np.mean(y_1-y_0)\n",
    "    samplePho4CountPreds[key] = np.mean(np.exp(y_1)-np.exp(y_0))\n",
    "    y_0 = np.array(flankToPBCbf1Preds[key][0]).astype(float)\n",
    "    y_1 = np.array(flankToPBCbf1Preds[key][1]).astype(float)\n",
    "    samplePBCbf1LogPreds[key] = np.mean(y_1-y_0)\n",
    "    samplePBCbf1Preds[key] = np.mean(np.exp(y_1)-np.exp(y_0))\n",
    "    y_1 = np.array(flankToChPCbf1Preds[key]).astype(float)\n",
    "    sampleChPCbf1LogPreds[key] = np.mean(y_1)\n",
    "    sampleChPCbf1Preds[key] = np.mean(np.exp(y_1)-1)\n",
    "for key in sampled_valid_keys:\n",
    "    y_0 = np.array(flankToPho4CountPreds[key][0]).astype(float)\n",
    "    y_1 = np.array(flankToPho4CountPreds[key][1]).astype(float)\n",
    "    samplePho4LogCountPreds[key] = np.mean(y_1-y_0)\n",
    "    samplePho4CountPreds[key] = np.mean(np.exp(y_1)-np.exp(y_0))\n",
    "    y_0 = np.array(flankToPBCbf1Preds[key][0]).astype(float)\n",
    "    y_1 = np.array(flankToPBCbf1Preds[key][1]).astype(float)\n",
    "    samplePBCbf1LogPreds[key] = np.mean(y_1-y_0)\n",
    "    samplePBCbf1Preds[key] = np.mean(np.exp(y_1)-np.exp(y_0))\n",
    "    y_1 = np.array(flankToChPCbf1Preds[key]).astype(float)\n",
    "    sampleChPCbf1LogPreds[key] = np.mean(y_1)\n",
    "    sampleChPCbf1Preds[key] = np.mean(np.exp(y_1)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plotCorrs(xvals, yvals, xlabel, ylabel, filename):\n",
    "    xy = np.vstack([xvals,yvals])\n",
    "    z = gaussian_kde(xy)(xy)\n",
    "    smallFont = {'size' : 20}\n",
    "    plt.rc('font', **smallFont)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(xvals, yvals, c=z, edgecolor='', alpha=0.1)\n",
    "    axes = plt.gca()\n",
    "    fig.set_size_inches(20, 10)\n",
    "    p, residuals, _, _, _ = np.polyfit(xvals, yvals, 1, full=True)\n",
    "    m, b = p\n",
    "    X_plot = np.linspace(axes.get_xlim()[0],axes.get_xlim()[1],100)\n",
    "    plt.plot(X_plot, m*X_plot + b, '-')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(\"spearman: \"+str(spearmanr(xvals, yvals))+\n",
    "              \", pearson: \"+str(pearsonr(xvals, yvals))+\n",
    "              \", residuals: \"+str(residuals))\n",
    "    plt.savefig(filename+'.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pho4 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_log_preacts = []\n",
    "valid_preacts = []\n",
    "valid_labels = []\n",
    "for key in sampled_valid_keys:\n",
    "    valid_log_preacts.append(samplePho4LogCountPreds[key])\n",
    "    valid_preacts.append(samplePho4CountPreds[key])\n",
    "    valid_labels.append(flankToPho4Ddg[key])\n",
    "valid_log_preacts = np.array(valid_log_preacts)\n",
    "valid_preacts = np.array(valid_preacts)\n",
    "valid_labels = np.array(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrs(valid_log_preacts, valid_labels, \"delta log counts\", \"ddG\", \"Pho4_uncalibrated_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pho4 baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preacts = []\n",
    "preacts = []\n",
    "labels = []\n",
    "for key in sampled_keys:\n",
    "    log_preacts.append(samplePho4LogCountPreds[key])\n",
    "    preacts.append(samplePho4CountPreds[key])\n",
    "    labels.append(flankToPho4Ddg[key])\n",
    "log_preacts = np.array(log_preacts)\n",
    "preacts = np.array(preacts)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrs(log_preacts, labels, \"delta log counts\", \"ddG\", \"Pho4_uncalibrated_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pho4 logit fit with log counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.024108\n",
      "         Iterations: 432\n",
      "         Function evaluations: 3530\n",
      "         Gradient evaluations: 704\n",
      "multiplier:  794.0891036334393 , in sigmoid bias:  5.691423964670937 , out of sigmoid bias:  -789.5987353007678\n"
     ]
    }
   ],
   "source": [
    "sf = SigmoidFit()\n",
    "calibration_func, inv_func = sf(valid_log_preacts, valid_labels)\n",
    "calibrated_labels = inv_func(log_preacts)\n",
    "plotCorrs(calibrated_labels, labels, \"predicted ddG\", \"true ddG\", \"Pho4_calibrated_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChIPexo Cbf1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_log_preacts = []\n",
    "valid_preacts = []\n",
    "valid_labels = []\n",
    "for key in sampled_valid_keys:\n",
    "    valid_log_preacts.append(sampleChPCbf1LogPreds[key])\n",
    "    valid_preacts.append(sampleChPCbf1Preds[key])\n",
    "    valid_labels.append(flankToCbf1Ddg[key])\n",
    "valid_log_preacts = np.array(valid_log_preacts)\n",
    "valid_preacts = np.array(valid_preacts)\n",
    "valid_labels = np.array(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrs(valid_log_preacts, valid_labels, \"delta log counts\", \"ddG\", \"Cbf1_ChIPexo_uncalibrated_sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChIPexo Cbf1 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preacts = []\n",
    "preacts = []\n",
    "labels = []\n",
    "for key in sampled_keys:\n",
    "    log_preacts.append(sampleChPCbf1LogPreds[key])\n",
    "    preacts.append(sampleChPCbf1Preds[key])\n",
    "    labels.append(flankToCbf1Ddg[key])\n",
    "log_preacts = np.array(log_preacts)\n",
    "preacts = np.array(preacts)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrs(log_preacts, labels, \"delta log counts\", \"ddG\", \"Cbf1_ChIPexo_uncalibrated_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChIPexo Cbf1 logit fit with log counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = SigmoidFit()\n",
    "calibration_func, inv_func = sf(valid_log_preacts, valid_labels)\n",
    "calibrated_labels = inv_func(log_preacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrs(calibrated_labels, labels, \"predicted ddG\", \"true ddG\", \"Cbf1_ChIPexo_calibrated_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basepair]",
   "language": "python",
   "name": "conda-env-basepair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
