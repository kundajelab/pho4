{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_genomics\n",
    "from keras_genomics.layers.convolutional import RevCompConv1D\n",
    "import keras\n",
    "import keras.layers as kl\n",
    "from keras import backend as K \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from seqdataloader.batchproducers import coordbased\n",
    "from seqdataloader.batchproducers.coordbased import coordstovals\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchproducers\n",
    "from seqdataloader.batchproducers.coordbased import coordbatchtransformers\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope\n",
    "import json\n",
    "import gzip\n",
    "import codecs\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr, gaussian_kde\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqToDdg = {}\n",
    "firstLine = True\n",
    "allFlanks = []\n",
    "with open(\"data/experimental/all_predicted_ddGs.csv\") as inp:\n",
    "    for line in inp:\n",
    "        if firstLine:\n",
    "            firstLine = False\n",
    "            continue\n",
    "        flank, Cbf1_ddg, Pho4_ddg = line.strip().split(',')\n",
    "        seqToDdg[flank] = float(Cbf1_ddg)\n",
    "        allFlanks.append(flank)\n",
    "\n",
    "sampled_keys = np.random.choice(allFlanks, 10000, replace=False)\n",
    "xvals = []\n",
    "for curr_seq in sampled_keys:\n",
    "    xvals.append(seqToDdg[curr_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastapath = \"data/genome/male.hg19.fa\"\n",
    "GenomeDict={}\n",
    "sequence=''\n",
    "inputdatafile = open(fastapath)\n",
    "for line in inputdatafile:\n",
    "    if line[0]=='>':\n",
    "        if sequence != '':\n",
    "            GenomeDict[chrm] = ''.join(sequence)\n",
    "        chrm = line.strip().split('>')[1]\n",
    "        sequence=[]\n",
    "        Keep=False\n",
    "        continue\n",
    "    else:\n",
    "        sequence.append(line.strip())\n",
    "GenomeDict[chrm] = ''.join(sequence)\n",
    "\n",
    "seq_len = 1346\n",
    "out_pred_len = 1000\n",
    "test_chrms = [\"chr1\", \"chr8\", \"chr21\"]\n",
    "seq_peaks = []\n",
    "with gzip.open(\"data/cbf1_hg19/cbf1.hg19.bed.gz\", 'rt') as inp:\n",
    "    for line in inp:\n",
    "        chrm = line.strip().split('\\t')[0]\n",
    "        if chrm not in test_chrms:\n",
    "            continue\n",
    "        pStart = int(line.strip().split('\\t')[1])\n",
    "        summit = pStart + int(line.strip().split('\\t')[-1])\n",
    "        start = int(summit - (seq_len/2))\n",
    "        end = int(summit + (seq_len/2))\n",
    "        seq_peaks.append(GenomeDict[chrm][start:end].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrdict = {'a':[1,0,0,0],'c':[0,1,0,0],'g':[0,0,1,0],'t':[0,0,0,1],\n",
    "           'n':[0,0,0,0],'A':[1,0,0,0],'C':[0,1,0,0],'G':[0,0,1,0],\n",
    "           'T':[0,0,0,1],'N':[0,0,0,0]}\n",
    "def getOneHot(ISM_sequences):\n",
    "  # takes in list of sequences\n",
    "    one_hot_seqs = []\n",
    "    for seq in ISM_sequences:\n",
    "        one_hot = []\n",
    "        for i in range(len(seq)):\n",
    "            one_hot.append(ltrdict[seq[i:i+1]])\n",
    "        one_hot_seqs.append(one_hot)\n",
    "    return np.array(one_hot_seqs)\n",
    "\n",
    "def multinomial_nll(true_counts, logits):\n",
    "    \"\"\"Compute the multinomial negative log-likelihood\n",
    "    Args:\n",
    "      true_counts: observed count values\n",
    "      logits: predicted logit values\n",
    "    \"\"\"\n",
    "    counts_per_example = tf.reduce_sum(true_counts, axis=-1)\n",
    "    dist = tfp.distributions.Multinomial(total_count=counts_per_example,\n",
    "                                         logits=logits)\n",
    "    return (-tf.reduce_sum(dist.log_prob(true_counts)) / \n",
    "            tf.to_float(tf.shape(true_counts)[0]))\n",
    "\n",
    "#from https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/basepair/losses.py#L87\n",
    "class MultichannelMultinomialNLL(object):\n",
    "    def __init__(self, n):\n",
    "        self.__name__ = \"MultichannelMultinomialNLL\"\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, true_counts, logits):\n",
    "        for i in range(self.n):\n",
    "            loss = multinomial_nll(true_counts[..., i], logits[..., i])\n",
    "            if i == 0:\n",
    "                total = loss\n",
    "            else:\n",
    "                total += loss\n",
    "        return total\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"n\": self.n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CustomObjectScope({'MultichannelMultinomialNLL': MultichannelMultinomialNLL,'RevCompConv1D': RevCompConv1D}):\n",
    "    model = load_model(\"data/models/cbf1_hg19_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplift.dinuc_shuffle import dinuc_shuffle\n",
    "\n",
    "num_samples = 10\n",
    "yvals = []\n",
    "for flank in sampled_keys:\n",
    "    pre_seqs = []\n",
    "    post_seqs = []\n",
    "    insert = flank[:5] + \"CACGTG\" + flank[5:]\n",
    "    insert_len = len(insert)\n",
    "    start = int((seq_len/2)-(insert_len/2))\n",
    "    indices = np.random.choice(len(seq_peaks), num_samples, replace=False)\n",
    "    for idx in indices:\n",
    "        pre_seq = dinuc_shuffle(seq_peaks[idx])\n",
    "        post_seq = pre_seq[:start] + insert + pre_seq[start+insert_len:]\n",
    "        pre_seqs.append(pre_seq)\n",
    "        post_seqs.append(post_seq)\n",
    "    pre = model.predict([getOneHot(pre_seqs), np.zeros((num_samples,)), np.zeros((num_samples,out_pred_len,2))])\n",
    "    post = model.predict([getOneHot(post_seqs), np.zeros((num_samples,)), np.zeros((num_samples,out_pred_len,2))])\n",
    "    yvals.append(np.mean(post[0]-pre[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.vstack([xvals,yvals])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "smallFont = {'size' : 10}\n",
    "plt.rc('font', **smallFont)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xvals, yvals, c=z, edgecolor='', alpha=0.1)\n",
    "plt.xlabel(\"DDG\")\n",
    "plt.ylabel(\"Delta Log Counts\")\n",
    "plt.title(\"DDG vs model predictions: \"+str(spearmanr(xvals, yvals)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basepair]",
   "language": "python",
   "name": "conda-env-basepair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
